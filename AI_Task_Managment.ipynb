{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Munshid-mhd/AI-TASK-MANAGMENT-SYSTEM/blob/main/AI_Task_Managment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xY1VOz1g5eaR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I48y3Z_hph1n",
        "outputId": "a0ba72fc-08f5-4f42-bd35-ef6a8f9db748"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GCeSiVYdp8-7",
        "outputId": "494b45c4-6305-4afd-cc68-ad1710c05968"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-687962cf-1334-487e-88c6-94b8bc2e09a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-687962cf-1334-487e-88c6-94b8bc2e09a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving synthetic_task_dataset.csv.csv to synthetic_task_dataset.csv.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uhpsqxoXgsGU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec167c99"
      },
      "source": [
        "file_name=list(uploaded.keys())[0]\n",
        "df=pd.read_csv(file_name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRzUuwQJnCkl",
        "outputId": "9a619a24-5653-4960-b378-21e5279cac1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   task_id                task_name  \\\n",
            "0        1    Memory class recently   \n",
            "1        2    Election unit feeling   \n",
            "2        3            Live security   \n",
            "3        4               Mrs finish   \n",
            "4        5  More fight character we   \n",
            "\n",
            "                                         description priority       status  \\\n",
            "0  Condition pass science unit admit lawyer share...      Low    Completed   \n",
            "1  Few plan goal myself response into information...     High    Completed   \n",
            "2  Establish begin candidate always resource play...     High      Pending   \n",
            "3  Capital late production perform today sometime...      Low  In Progress   \n",
            "4  Avoid herself occur single general huge answer...   Medium    Completed   \n",
            "\n",
            "  assigned_user    deadline  \n",
            "0           Joe  2025-11-11  \n",
            "1    Alexandria  2025-10-28  \n",
            "2        Krista  2025-11-02  \n",
            "3        Angela  2025-11-10  \n",
            "4      Jennifer  2025-11-07  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eda\n"
      ],
      "metadata": {
        "id": "XOZx5D8U0XFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- data types \")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj1BcYOcsSNE",
        "outputId": "1b36a9f7-dee9-495e-a536-221105d6c9f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- data types \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 7 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   task_id        100 non-null    int64 \n",
            " 1   task_name      100 non-null    object\n",
            " 2   description    100 non-null    object\n",
            " 3   priority       100 non-null    object\n",
            " 4   status         100 non-null    object\n",
            " 5   assigned_user  100 non-null    object\n",
            " 6   deadline       100 non-null    object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 5.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n-- missing values\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbY6hUzFuyG4",
        "outputId": "85ae0e5a-ecfb-40e6-c9d1-3567d4600173"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- missing values\n",
            "task_id          0\n",
            "task_name        0\n",
            "description      0\n",
            "priority         0\n",
            "status           0\n",
            "assigned_user    0\n",
            "deadline         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n---repeated raws count {df.duplicated().sum()}--\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV0EYduBu0xK",
        "outputId": "64208204-7249-4f1d-814a-aca94ce5f6c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---repeated raws count 0--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols=['priority','status','assigned_user']\n",
        "for col in categorical_cols:\n",
        "  print(f\"\\n---'{col}'unique values and occurences in the column ---\")\n",
        "  print(\"Unique Values:\",df[col].unique())\n",
        "  print(\"freequent count\")\n",
        "  print(df[col].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1buZiED9vaH6",
        "outputId": "040ca1c6-76be-4b5c-c539-6543a6a81612"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---'priority'unique values and occurences in the column ---\n",
            "Unique Values: ['Low' 'High' 'Medium']\n",
            "freequent count\n",
            "priority\n",
            "Medium    36\n",
            "Low       32\n",
            "High      32\n",
            "Name: count, dtype: int64\n",
            "\n",
            "---'status'unique values and occurences in the column ---\n",
            "Unique Values: ['Completed' 'Pending' 'In Progress']\n",
            "freequent count\n",
            "status\n",
            "In Progress    41\n",
            "Pending        32\n",
            "Completed      27\n",
            "Name: count, dtype: int64\n",
            "\n",
            "---'assigned_user'unique values and occurences in the column ---\n",
            "Unique Values: ['Joe' 'Alexandria' 'Krista' 'Angela' 'Jennifer' 'James' 'Mary' 'Stacie'\n",
            " 'Alicia' 'John' 'Glenn' 'Joanna' 'Terri' 'Brian' 'Ashley' 'Michael'\n",
            " 'Timothy' 'Eric' 'Cynthia' 'Katherine' 'Alexa' 'Scott' 'Stephen' 'Lisa'\n",
            " 'Kathy' 'Adrienne' 'Aaron' 'Robert' 'Mark' 'Harold' 'Bethany' 'Kimberly'\n",
            " 'Marissa' 'Jessica' 'Grant' 'Alec' 'Tracy' 'Joseph' 'Kristen' 'Trevor'\n",
            " 'Heather' 'Jacqueline' 'Jason' 'Carolyn' 'Ethan' 'Eduardo' 'Tyrone'\n",
            " 'Jill' 'Matthew' 'Troy' 'Chris' 'Allen' 'Amanda' 'Philip' 'Thomas'\n",
            " 'Nancy' 'Edward' 'Laura' 'William' 'Elizabeth' 'Jeffrey' 'Bailey'\n",
            " 'Claudia' 'Sarah' 'Holly' 'Benjamin' 'Debra' 'Nicole' 'Albert' 'Richard'\n",
            " 'Autumn' 'David' 'Melissa' 'Tiffany' 'Karen' 'Erin' 'Shawna' 'Amy'\n",
            " 'Mackenzie' 'Kevin']\n",
            "freequent count\n",
            "assigned_user\n",
            "Robert       5\n",
            "Michael      3\n",
            "Katherine    3\n",
            "Mark         3\n",
            "Cynthia      2\n",
            "            ..\n",
            "Erin         1\n",
            "Shawna       1\n",
            "Amy          1\n",
            "Mackenzie    1\n",
            "Kevin        1\n",
            "Name: count, Length: 80, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning\n"
      ],
      "metadata": {
        "id": "iclxcz2L0JbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if'unnamed:0' in df.columns:\n",
        "  df.drop('unnamed:0', axis=1, inplace=True)\n",
        "  print(\"\\n 'unnamed:0' removed unnecessary column\")"
      ],
      "metadata": {
        "id": "nkCTkCAivY2r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['assigned_user'].fillna('unnassinged',inplace=True)\n",
        "print(\"\\n Missing values in 'assigned_user' were filled in with 'unnassigned'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbHvEuQXytBu",
        "outputId": "5e912cd5-62f9-47d4-cf42-dd1bbb883c7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Missing values in 'assigned_user' were filled in with 'unnassigned'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3507055451.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['assigned_user'].fillna('unnassinged',inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Corrected Date Processing Code ---\n",
        "\n",
        "# Use the EXACT column name: 'deadline'\n",
        "date_col = 'deadline'\n",
        "\n",
        "if date_col in df.columns:\n",
        "    # 1. Convert the column to datetime objects (fixing the KeyError)\n",
        "    # The 'errors='coerce'' handles any non-date values by turning them into NaT\n",
        "    df['deadline'] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "\n",
        "    # 2. Extract useful features (Feature Engineering)\n",
        "    # Check if the conversion was successful (i.e., not all NaT) before proceeding\n",
        "    if df['deadline'].isnull().all() == False:\n",
        "        df['due_day_of_week'] = df['deadline'].dt.day_name()\n",
        "        df['is_due_weekend'] = df['deadline'].dt.weekday.apply(lambda x: 1 if x >= 5 else 0)\n",
        "        print(f\"\\n✅ '{date_col}' column processed and new features added.\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ Warning: The '{date_col}' column contains no valid dates and could not be processed.\")\n",
        "else:\n",
        "    print(f\"\\n❌ Critical Error: Column '{date_col}' not found. Please re-check column names.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuiOKVnezuxp",
        "outputId": "7da78d6e-5ff5-493c-da7b-648b19edd154"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 'deadline' column processed and new features added.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMgOwmQn4LEm",
        "outputId": "e37e6c0d-1918-4736-d0ef-571518e4a660"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['task_id', 'task_name', 'description', 'priority', 'status',\n",
            "       'assigned_user', 'deadline', 'due_day_of_week', 'is_due_weekend'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nlp preprocessing on description"
      ],
      "metadata": {
        "id": "pAlFSszM-rle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Lemmatizer and Stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Performs text preprocessing: lowercasing, punctuation/number removal,\n",
        "    stop word removal, and lemmatization.\n",
        "    \"\"\"\n",
        "    # 1. Lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Remove special characters and numbers, keeping only letters and spaces\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # 3. Tokenization and Stop Word Removal\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stop words\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # 4. Lemmatization\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    # 5. Join the words back into a single string\n",
        "    return ' '.join(words)\n",
        "\n",
        "# --- Apply the cleaning function to the 'task_name' and 'description' columns ---\n",
        "\n",
        "# Create new columns to store the cleaned text\n",
        "df['cleaned_task_name'] = df['task_name'].apply(clean_text)\n",
        "df['cleaned_description'] = df['description'].apply(clean_text)\n",
        "\n",
        "print(\"✅ Text preprocessing complete for 'task_name' and 'description'.\")\n",
        "print(\"\\n--- Example of Cleaned Data (First Row) ---\")\n",
        "print(f\"Original Task Name: {df['task_name'].iloc[0]}\")\n",
        "print(f\"Cleaned Task Name: {df['cleaned_task_name'].iloc[0]}\")\n",
        "print(f\"Original Description: {df['description'].iloc[0]}\")\n",
        "print(f\"Cleaned Description: {df['cleaned_description'].iloc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOpcVOKM9wvl",
        "outputId": "797c5217-7177-401e-a464-50f878db6d5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Text preprocessing complete for 'task_name' and 'description'.\n",
            "\n",
            "--- Example of Cleaned Data (First Row) ---\n",
            "Original Task Name: Memory class recently\n",
            "Cleaned Task Name: memory class recently\n",
            "Original Description: Condition pass science unit admit lawyer share prepare of fill organization foot.\n",
            "Cleaned Description: condition pas science unit admit lawyer share prepare fill organization foot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPv-QrkI4nlr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6869ff0"
      },
      "source": [
        "# Task\n",
        "Perform feature extraction on the `cleaned_task_name` and `cleaned_description` columns of the dataframe using a suitable method (TF-IDF or word embeddings) and provide the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb143f4f"
      },
      "source": [
        "## Choose a feature extraction method\n",
        "\n",
        "### Subtask:\n",
        "Decide whether to use TF-IDF or a word embedding technique (like Word2Vec or BERT).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b363e998"
      },
      "source": [
        "## Implement the chosen method\n",
        "\n",
        "### Subtask:\n",
        "Implement the chosen feature extraction method (TF-IDF) on the `cleaned_task_name` and `cleaned_description` columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d32af515"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the chosen feature extraction method (TF-IDF) on the `cleaned_task_name` and `cleaned_description` columns by importing `TfidfVectorizer` and applying it to both columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf210335",
        "outputId": "d97c235f-f99f-4dfe-9086-6eb69bad39e8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create an instance of TfidfVectorizer\n",
        "# Using a new instance for each column to have separate vocabularies\n",
        "tfidf_task_name = TfidfVectorizer()\n",
        "tfidf_description = TfidfVectorizer()\n",
        "\n",
        "# Apply TF-IDF to the 'cleaned_task_name' column\n",
        "tfidf_matrix_task_name = tfidf_task_name.fit_transform(df['cleaned_task_name'])\n",
        "\n",
        "# Apply TF-IDF to the 'cleaned_description' column\n",
        "tfidf_matrix_description = tfidf_description.fit_transform(df['cleaned_description'])\n",
        "\n",
        "print(\"✅ TF-IDF feature extraction complete for 'cleaned_task_name' and 'cleaned_description'.\")\n",
        "print(f\"TF-IDF matrix shape for task name: {tfidf_matrix_task_name.shape}\")\n",
        "print(f\"TF-IDF matrix shape for description: {tfidf_matrix_description.shape}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TF-IDF feature extraction complete for 'cleaned_task_name' and 'cleaned_description'.\n",
            "TF-IDF matrix shape for task name: (100, 198)\n",
            "TF-IDF matrix shape for description: (100, 557)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98f1d5c0"
      },
      "source": [
        "## Examine the output\n",
        "\n",
        "### Subtask:\n",
        "Examine the resulting TF-IDF matrices to understand their structure and how they represent the text data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "394a9ae0"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the shape of the TF-IDF matrices and a small portion of them to understand their structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6776b17f",
        "outputId": "59703767-8517-4bec-991c-2ea330a7f63b"
      },
      "source": [
        "print(\"\\n--- TF-IDF Matrix Shapes ---\")\n",
        "print(f\"TF-IDF matrix shape for task name: {tfidf_matrix_task_name.shape}\")\n",
        "print(f\"TF-IDF matrix shape for description: {tfidf_matrix_description.shape}\")\n",
        "\n",
        "print(\"\\n--- Sample of TF-IDF Matrix (Task Name) ---\")\n",
        "# Convert a small slice to dense array for viewing\n",
        "print(tfidf_matrix_task_name[:5, :10].toarray())\n",
        "\n",
        "print(\"\\n--- Sample of TF-IDF Matrix (Description) ---\")\n",
        "# Convert a small slice to dense array for viewing\n",
        "print(tfidf_matrix_description[:5, :10].toarray())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TF-IDF Matrix Shapes ---\n",
            "TF-IDF matrix shape for task name: (100, 198)\n",
            "TF-IDF matrix shape for description: (100, 557)\n",
            "\n",
            "--- Sample of TF-IDF Matrix (Task Name) ---\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "--- Sample of TF-IDF Matrix (Description) ---\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.30975587 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8d9ad73"
      },
      "source": [
        "**Reasoning**:\n",
        "Get and print the feature names (words) from the TF-IDF vectorizers for both task names and descriptions to understand the vocabulary used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8928cd6",
        "outputId": "bf99988a-b3ef-4cb6-fd5a-56d41856a1d5"
      },
      "source": [
        "# Get feature names (words) for task names\n",
        "feature_names_task_name = tfidf_task_name.get_feature_names_out()\n",
        "print(\"\\n--- Sample Feature Names (Task Name) ---\")\n",
        "print(feature_names_task_name[:10]) # Print first 10 feature names\n",
        "\n",
        "# Get feature names (words) for descriptions\n",
        "feature_names_description = tfidf_description.get_feature_names_out()\n",
        "print(\"\\n--- Sample Feature Names (Description) ---\")\n",
        "print(feature_names_description[:10]) # Print first 10 feature names"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample Feature Names (Task Name) ---\n",
            "['able' 'account' 'act' 'adult' 'age' 'air' 'along' 'american' 'animal'\n",
            " 'another']\n",
            "\n",
            "--- Sample Feature Names (Description) ---\n",
            "['able' 'account' 'across' 'actually' 'add' 'address' 'administration'\n",
            " 'admit' 'adult' 'affect']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bb6cb10"
      },
      "source": [
        "**Reasoning**:\n",
        "Briefly interpret the structure and values in the TF-IDF matrices based on the shapes and sample data printed earlier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78583a1a",
        "outputId": "1ca9395e-042b-4114-9fc5-8500a39ba765"
      },
      "source": [
        "print(\"\\n--- Interpretation of TF-IDF Matrices ---\")\n",
        "print(f\"The TF-IDF matrix for task names has a shape of {tfidf_matrix_task_name.shape}, meaning there are {tfidf_matrix_task_name.shape[0]} task entries and {tfidf_matrix_task_name.shape[1]} unique words (features) across all task names after preprocessing.\")\n",
        "print(f\"The TF-IDF matrix for descriptions has a shape of {tfidf_matrix_description.shape}, indicating {tfidf_matrix_description.shape[0]} description entries and {tfidf_matrix_description.shape[1]} unique words (features) across all descriptions after preprocessing.\")\n",
        "print(\"\\nBoth matrices are sparse, as seen from the sample outputs which contain many zeros. This is expected in TF-IDF matrices, where most documents only contain a small subset of the total vocabulary.\")\n",
        "print(\"The non-zero values in the matrices represent the TF-IDF score for a specific word in a specific document. A higher TF-IDF score indicates that the word is more important and relevant to that document compared to other documents in the corpus.\")\n",
        "print(\"For example, in the sample description matrix, the value 0.30975587 at the first row and eighth column means the word corresponding to the eighth feature name in the description vocabulary has this TF-IDF score in the first description.\")\n",
        "print(\"The feature names printed earlier ('able', 'account', etc.) are the words that form the columns of these matrices, representing the vocabulary learned by the TF-IDF vectorizers.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Interpretation of TF-IDF Matrices ---\n",
            "The TF-IDF matrix for task names has a shape of (100, 198), meaning there are 100 task entries and 198 unique words (features) across all task names after preprocessing.\n",
            "The TF-IDF matrix for descriptions has a shape of (100, 557), indicating 100 description entries and 557 unique words (features) across all descriptions after preprocessing.\n",
            "\n",
            "Both matrices are sparse, as seen from the sample outputs which contain many zeros. This is expected in TF-IDF matrices, where most documents only contain a small subset of the total vocabulary.\n",
            "The non-zero values in the matrices represent the TF-IDF score for a specific word in a specific document. A higher TF-IDF score indicates that the word is more important and relevant to that document compared to other documents in the corpus.\n",
            "For example, in the sample description matrix, the value 0.30975587 at the first row and eighth column means the word corresponding to the eighth feature name in the description vocabulary has this TF-IDF score in the first description.\n",
            "The feature names printed earlier ('able', 'account', etc.) are the words that form the columns of these matrices, representing the vocabulary learned by the TF-IDF vectorizers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4293e9b7"
      },
      "source": [
        "## Integrate with the dataframe (optional)\n",
        "\n",
        "### Subtask:\n",
        "Integrate the extracted TF-IDF features back into the main DataFrame if needed for further analysis or modeling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "922a8d4b"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the sparse TF-IDF matrices to dense arrays, create DataFrames from them, and concatenate them with the original DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "6eef5850",
        "outputId": "3391d84d-d889-40b1-a915-a8ca8bbd557b"
      },
      "source": [
        "# 1. Convert sparse TF-IDF matrices to dense arrays\n",
        "tfidf_task_name_dense = tfidf_matrix_task_name.toarray()\n",
        "tfidf_description_dense = tfidf_matrix_description.toarray()\n",
        "\n",
        "# Get feature names to use as column names\n",
        "feature_names_task_name = tfidf_task_name.get_feature_names_out()\n",
        "feature_names_description = tfidf_description.get_feature_names_out()\n",
        "\n",
        "# 2. Create new DataFrames from these dense arrays\n",
        "# Prefix column names to avoid collisions\n",
        "df_tfidf_task_name = pd.DataFrame(tfidf_task_name_dense, columns=[f'task_name_tfidf_{col}' for col in feature_names_task_name])\n",
        "df_tfidf_description = pd.DataFrame(tfidf_description_dense, columns=[f'description_tfidf_{col}' for col in feature_names_description])\n",
        "\n",
        "# 3. Concatenate the new DataFrames with the original DataFrame df\n",
        "# Ensure the indices align for correct concatenation\n",
        "df = pd.concat([df, df_tfidf_task_name, df_tfidf_description], axis=1)\n",
        "\n",
        "# 4. Print the first few rows of the updated DataFrame to verify the integration\n",
        "print(\"\\n--- Updated DataFrame with TF-IDF Features ---\")\n",
        "display(df.head())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Updated DataFrame with TF-IDF Features ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   task_id                task_name  \\\n",
              "0        1    Memory class recently   \n",
              "1        2    Election unit feeling   \n",
              "2        3            Live security   \n",
              "3        4               Mrs finish   \n",
              "4        5  More fight character we   \n",
              "\n",
              "                                         description priority       status  \\\n",
              "0  Condition pass science unit admit lawyer share...      Low    Completed   \n",
              "1  Few plan goal myself response into information...     High    Completed   \n",
              "2  Establish begin candidate always resource play...     High      Pending   \n",
              "3  Capital late production perform today sometime...      Low  In Progress   \n",
              "4  Avoid herself occur single general huge answer...   Medium    Completed   \n",
              "\n",
              "  assigned_user   deadline due_day_of_week  is_due_weekend  \\\n",
              "0           Joe 2025-11-11         Tuesday               0   \n",
              "1    Alexandria 2025-10-28         Tuesday               0   \n",
              "2        Krista 2025-11-02          Sunday               1   \n",
              "3        Angela 2025-11-10          Monday               0   \n",
              "4      Jennifer 2025-11-07          Friday               0   \n",
              "\n",
              "       cleaned_task_name  ... description_tfidf_wife  description_tfidf_wind  \\\n",
              "0  memory class recently  ...                    0.0                     0.0   \n",
              "1  election unit feeling  ...                    0.0                     0.0   \n",
              "2          live security  ...                    0.0                     0.0   \n",
              "3              mr finish  ...                    0.0                     0.0   \n",
              "4        fight character  ...                    0.0                     0.0   \n",
              "\n",
              "   description_tfidf_without  description_tfidf_word  description_tfidf_work  \\\n",
              "0                        0.0                     0.0                     0.0   \n",
              "1                        0.0                     0.0                     0.0   \n",
              "2                        0.0                     0.0                     0.0   \n",
              "3                        0.0                     0.0                     0.0   \n",
              "4                        0.0                     0.0                     0.0   \n",
              "\n",
              "   description_tfidf_world  description_tfidf_worry  description_tfidf_wrong  \\\n",
              "0                      0.0                      0.0                      0.0   \n",
              "1                      0.0                      0.0                      0.0   \n",
              "2                      0.0                      0.0                      0.0   \n",
              "3                      0.0                      0.0                      0.0   \n",
              "4                      0.0                      0.0                      0.0   \n",
              "\n",
              "   description_tfidf_yeah  description_tfidf_yet  \n",
              "0                     0.0                    0.0  \n",
              "1                     0.0                    0.0  \n",
              "2                     0.0                    0.0  \n",
              "3                     0.0                    0.0  \n",
              "4                     0.0                    0.0  \n",
              "\n",
              "[5 rows x 766 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97810741-5ae7-4278-bbec-5833109079b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task_id</th>\n",
              "      <th>task_name</th>\n",
              "      <th>description</th>\n",
              "      <th>priority</th>\n",
              "      <th>status</th>\n",
              "      <th>assigned_user</th>\n",
              "      <th>deadline</th>\n",
              "      <th>due_day_of_week</th>\n",
              "      <th>is_due_weekend</th>\n",
              "      <th>cleaned_task_name</th>\n",
              "      <th>...</th>\n",
              "      <th>description_tfidf_wife</th>\n",
              "      <th>description_tfidf_wind</th>\n",
              "      <th>description_tfidf_without</th>\n",
              "      <th>description_tfidf_word</th>\n",
              "      <th>description_tfidf_work</th>\n",
              "      <th>description_tfidf_world</th>\n",
              "      <th>description_tfidf_worry</th>\n",
              "      <th>description_tfidf_wrong</th>\n",
              "      <th>description_tfidf_yeah</th>\n",
              "      <th>description_tfidf_yet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Memory class recently</td>\n",
              "      <td>Condition pass science unit admit lawyer share...</td>\n",
              "      <td>Low</td>\n",
              "      <td>Completed</td>\n",
              "      <td>Joe</td>\n",
              "      <td>2025-11-11</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>0</td>\n",
              "      <td>memory class recently</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Election unit feeling</td>\n",
              "      <td>Few plan goal myself response into information...</td>\n",
              "      <td>High</td>\n",
              "      <td>Completed</td>\n",
              "      <td>Alexandria</td>\n",
              "      <td>2025-10-28</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>0</td>\n",
              "      <td>election unit feeling</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Live security</td>\n",
              "      <td>Establish begin candidate always resource play...</td>\n",
              "      <td>High</td>\n",
              "      <td>Pending</td>\n",
              "      <td>Krista</td>\n",
              "      <td>2025-11-02</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>1</td>\n",
              "      <td>live security</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mrs finish</td>\n",
              "      <td>Capital late production perform today sometime...</td>\n",
              "      <td>Low</td>\n",
              "      <td>In Progress</td>\n",
              "      <td>Angela</td>\n",
              "      <td>2025-11-10</td>\n",
              "      <td>Monday</td>\n",
              "      <td>0</td>\n",
              "      <td>mr finish</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>More fight character we</td>\n",
              "      <td>Avoid herself occur single general huge answer...</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Completed</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>2025-11-07</td>\n",
              "      <td>Friday</td>\n",
              "      <td>0</td>\n",
              "      <td>fight character</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 766 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97810741-5ae7-4278-bbec-5833109079b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97810741-5ae7-4278-bbec-5833109079b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97810741-5ae7-4278-bbec-5833109079b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c54bbed-3d9a-4f23-ae21-c05979379dd1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c54bbed-3d9a-4f23-ae21-c05979379dd1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c54bbed-3d9a-4f23-ae21-c05979379dd1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8e33e84"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   TF-IDF was selected as the feature extraction method due to its simplicity, efficiency, and suitability for the given text data characteristics (relatively short text with varied vocabulary).\n",
        "*   TF-IDF vectorization was successfully applied to the `cleaned_task_name` and `cleaned_description` columns separately.\n",
        "*   The TF-IDF matrix for task names has a shape of (100, 198), representing 100 task entries and 198 unique words (features).\n",
        "*   The TF-IDF matrix for descriptions has a shape of (100, 557), representing 100 description entries and 557 unique words (features).\n",
        "*   Both TF-IDF matrices are sparse, indicating that each document (task entry or description) contains only a subset of the total vocabulary.\n",
        "*   The non-zero values in the matrices represent the TF-IDF score for a specific word in a specific document, indicating its importance and relevance.\n",
        "*   The extracted TF-IDF features were successfully integrated into the main DataFrame, adding 198 new columns for task name features and 557 new columns for description features.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The extracted TF-IDF features can now be used as input for various machine learning models for tasks such as clustering, classification, or similarity analysis.\n",
        "*   Further exploration of the most important features (words) based on their TF-IDF scores could provide insights into the key terms describing the tasks and descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b9X1k-gchiCj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7efd00e"
      },
      "source": [
        "# Task\n",
        "Implement task classification using Naive Bayes and SVM on the extracted features from the previous steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f3d8cf1"
      },
      "source": [
        "## Prepare data for modeling\n",
        "\n",
        "### Subtask:\n",
        "Separate the features (the TF-IDF matrices) and the target variable (you'll need to decide which column is your target, e.g., 'status' or 'priority').\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efc5a99"
      },
      "source": [
        "**Reasoning**:\n",
        "Select the TF-IDF feature columns and the target variable 'status' from the DataFrame to prepare for model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "046c8324",
        "outputId": "d65092f9-126b-4cc4-d331-6c6f531f7d7d"
      },
      "source": [
        "# Choose 'status' as the target variable for classification\n",
        "target_variable = 'status'\n",
        "\n",
        "# Select the columns containing TF-IDF features for task name and description\n",
        "tfidf_features_task_name_cols = [col for col in df.columns if col.startswith('task_name_tfidf_')]\n",
        "tfidf_features_description_cols = [col for col in df.columns if col.startswith('description_tfidf_')]\n",
        "\n",
        "# Combine the lists of TF-IDF feature columns\n",
        "all_tfidf_feature_cols = tfidf_features_task_name_cols + tfidf_features_description_cols\n",
        "\n",
        "# Create the feature matrix X by selecting the TF-IDF feature columns\n",
        "X = df[all_tfidf_feature_cols]\n",
        "\n",
        "# Create the target variable vector y by selecting the target column\n",
        "y = df[target_variable]\n",
        "\n",
        "# Print the shapes of X and y to verify\n",
        "print(f\"Shape of features (X): {X.shape}\")\n",
        "print(f\"Shape of target variable (y): {y.shape}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of features (X): (100, 755)\n",
            "Shape of target variable (y): (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "536912a3"
      },
      "source": [
        "## Split data\n",
        "\n",
        "### Subtask:\n",
        "Split the data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123c98ae"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the feature matrix X and the target variable y into training and testing sets and print their shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c00faedf",
        "outputId": "bbaa4c9c-015f-4c72-9e9a-c7d8daa7e739"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (80, 755)\n",
            "Shape of X_test: (20, 755)\n",
            "Shape of y_train: (80,)\n",
            "Shape of y_test: (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f655e4ed"
      },
      "source": [
        "## Train naive bayes model\n",
        "\n",
        "### Subtask:\n",
        "Train a Naive Bayes classifier on the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c38a5134"
      },
      "source": [
        "**Reasoning**:\n",
        "Train a Multinomial Naive Bayes classifier on the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5f9b9ba",
        "outputId": "a62ab492-6fde-4212-b4d8-645e9da8ca0a"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Instantiate a MultinomialNB model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Train the Naive Bayes model on the training data\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"✅ Multinomial Naive Bayes model trained successfully.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Multinomial Naive Bayes model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c155eeb"
      },
      "source": [
        "## Evaluate naive bayes model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the Naive Bayes model on the testing data using appropriate metrics (e.g., accuracy, precision, recall, F1-score).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3781f45f"
      },
      "source": [
        "**Reasoning**:\n",
        "Import evaluation metrics, make predictions with the trained Naive Bayes model, calculate accuracy, precision, recall, and F1-score, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5edd9d",
        "outputId": "9c7f78bd-6779-421e-de44-6430eabdc877"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb, average='weighted')\n",
        "recall_nb = recall_score(y_test, y_pred_nb, average='weighted')\n",
        "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"\\n--- Naive Bayes Model Evaluation ---\")\n",
        "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
        "print(f\"Precision: {precision_nb:.4f}\")\n",
        "print(f\"Recall: {recall_nb:.4f}\")\n",
        "print(f\"F1-score: {f1_nb:.4f}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Naive Bayes Model Evaluation ---\n",
            "Accuracy: 0.4000\n",
            "Precision: 0.5000\n",
            "Recall: 0.4000\n",
            "F1-score: 0.3100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7218a60"
      },
      "source": [
        "## Train svm model\n",
        "\n",
        "### Subtask:\n",
        "Train an SVM classifier on the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "406559d9"
      },
      "source": [
        "**Reasoning**:\n",
        "Train an SVM classifier on the training data using the provided instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7812d5f8",
        "outputId": "0341e8a9-ed13-41e3-e67c-c3965c53545d"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Instantiate an SVC model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Train the SVM model on the training data\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"✅ SVM classifier trained successfully.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SVM classifier trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0320eb3d"
      },
      "source": [
        "## Evaluate svm model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the SVM model on the testing data using the same metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "306d3f25"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the performance of the SVM model on the testing data using accuracy, precision, recall, and F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c94db5f",
        "outputId": "5dfdf0ab-907c-4062-c5b9-fded622d3097"
      },
      "source": [
        "# Make predictions on the testing data using the trained SVM model\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics for the SVM model\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, average='weighted', zero_division=0)\n",
        "recall_svm = recall_score(y_test, y_pred_svm, average='weighted', zero_division=0)\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='weighted', zero_division=0)\n",
        "\n",
        "# Print the evaluation metrics for the SVM model\n",
        "print(\"\\n--- SVM Model Evaluation ---\")\n",
        "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
        "print(f\"Precision: {precision_svm:.4f}\")\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "print(f\"F1-score: {f1_svm:.4f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SVM Model Evaluation ---\n",
            "Accuracy: 0.3000\n",
            "Precision: 0.0900\n",
            "Recall: 0.3000\n",
            "F1-score: 0.1385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ff9d0f"
      },
      "source": [
        "## Compare models\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance of the Naive Bayes and SVM models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf575ce"
      },
      "source": [
        "**Reasoning**:\n",
        "Compare the calculated evaluation metrics for both models and provide a brief comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75e96b5b",
        "outputId": "ee06f56f-f884-48af-dca3-bd3238c2582d"
      },
      "source": [
        "print(\"\\n--- Model Performance Comparison ---\")\n",
        "print(\"Metrics | Naive Bayes | SVM\")\n",
        "print(\"--------|-------------|-----\")\n",
        "print(f\"Accuracy | {accuracy_nb:.4f}    | {accuracy_svm:.4f}\")\n",
        "print(f\"Precision| {precision_nb:.4f}    | {precision_svm:.4f}\")\n",
        "print(f\"Recall   | {recall_nb:.4f}    | {recall_svm:.4f}\")\n",
        "print(f\"F1-score | {f1_nb:.4f}    | {f1_svm:.4f}\")\n",
        "\n",
        "print(\"\\n--- Comparison Summary ---\")\n",
        "if accuracy_nb > accuracy_svm:\n",
        "    print(\"The Naive Bayes model generally performed better than the SVM model based on accuracy, precision, recall, and F1-score.\")\n",
        "    print(\"Naive Bayes had higher accuracy (0.40 vs 0.30), precision (0.5000 vs 0.0900), recall (0.4000 vs 0.3000), and F1-score (0.3100 vs 0.1385).\")\n",
        "elif accuracy_svm > accuracy_nb:\n",
        "     print(\"The SVM model generally performed better than the Naive Bayes model based on accuracy, precision, recall, and F1-score.\")\n",
        "     print(\"SVM had higher accuracy (0.30 vs 0.40), precision (0.0900 vs 0.5000), recall (0.3000 vs 0.4000), and F1-score (0.1385 vs 0.3100).\")\n",
        "else:\n",
        "    print(\"Both models performed similarly in terms of accuracy.\")\n",
        "    print(\"However, Naive Bayes had higher precision (0.5000 vs 0.0900) and F1-score (0.3100 vs 0.1385), while recall was similar (0.4000 vs 0.3000).\")\n",
        "\n",
        "print(\"\\nPotential Reasons for Performance Differences:\")\n",
        "print(\"- Naive Bayes (specifically Multinomial Naive Bayes used here) is often a strong baseline for text classification due to its assumption of feature independence, which can work reasonably well with sparse TF-IDF data.\")\n",
        "print(\"- SVM's performance can be highly dependent on hyperparameter tuning (like the choice of kernel and regularization parameters), which was not performed here.\")\n",
        "print(\"- The limited size of the dataset (100 samples) might not be sufficient for either model to learn complex patterns effectively, potentially favoring the simpler Naive Bayes model in this instance.\")\n",
        "print(\"- The nature of the TF-IDF features and the complexity of the relationship between the text features and the 'status' classes could also contribute to the observed differences.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Performance Comparison ---\n",
            "Metrics | Naive Bayes | SVM\n",
            "--------|-------------|-----\n",
            "Accuracy | 0.4000    | 0.3000\n",
            "Precision| 0.5000    | 0.0900\n",
            "Recall   | 0.4000    | 0.3000\n",
            "F1-score | 0.3100    | 0.1385\n",
            "\n",
            "--- Comparison Summary ---\n",
            "The Naive Bayes model generally performed better than the SVM model based on accuracy, precision, recall, and F1-score.\n",
            "Naive Bayes had higher accuracy (0.40 vs 0.30), precision (0.5000 vs 0.0900), recall (0.4000 vs 0.3000), and F1-score (0.3100 vs 0.1385).\n",
            "\n",
            "Potential Reasons for Performance Differences:\n",
            "- Naive Bayes (specifically Multinomial Naive Bayes used here) is often a strong baseline for text classification due to its assumption of feature independence, which can work reasonably well with sparse TF-IDF data.\n",
            "- SVM's performance can be highly dependent on hyperparameter tuning (like the choice of kernel and regularization parameters), which was not performed here.\n",
            "- The limited size of the dataset (100 samples) might not be sufficient for either model to learn complex patterns effectively, potentially favoring the simpler Naive Bayes model in this instance.\n",
            "- The nature of the TF-IDF features and the complexity of the relationship between the text features and the 'status' classes could also contribute to the observed differences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ELINw_QZJS6g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1553a764"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The feature matrix `X` derived from combined TF-IDF features of 'task\\_name' and 'description' has a shape of (100, 755), while the target variable `y` ('status') has a shape of (100,).\n",
        "*   The data was split into training and testing sets with an 80/20 ratio. The training feature set (`X_train`) has a shape of (80, 755), the testing feature set (`X_test`) has a shape of (20, 755), the training target set (`y_train`) has a shape of (80,), and the testing target set (`y_test`) has a shape of (20,).\n",
        "*   The Naive Bayes model achieved an accuracy of 40%, a weighted precision of 50%, a weighted recall of 40%, and a weighted F1-score of 31% on the test set.\n",
        "*   The SVM model achieved an accuracy of 30%, a weighted precision of 9%, a weighted recall of 30%, and a weighted F1-score of 13.85% on the test set.\n",
        "*   The Naive Bayes model generally performed better than the SVM model across all evaluated metrics in this comparison.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The performance of both models is relatively low, suggesting that the current features or models may not be sufficient for accurate task status classification. Further feature engineering, model selection, or hyperparameter tuning is needed.\n",
        "*   The limited dataset size (100 samples) likely impacts model performance. Increasing the dataset size would be beneficial for training more robust models.\n"
      ]
    }
  ]
}